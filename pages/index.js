import { useRef, useState, useEffect, useMemo, useCallback } from 'react';
import { useRaf } from 'rooks';
import styled from 'styled-components';
import client from '../services/client';
import questionData from '../data/data.json';
import Head from 'next/head';
import Facade from '../components/elements/home/facade';
import Controls from '../components/elements/home/controls';
import Audio from '../components/elements/home/audio';
import { useWebAudio } from '../components/elements/home/audio';

const MAX_NUM_REPLAY = 2;

const Container = styled.div`background-color: #ffe156;`;

const Main = styled.main`
	position: relative;
	display: flex;
	flex-direction: column;
	align-items: center;
	padding: 1rem;
	height: 100%;
	overflow: hidden;
`;

export default function Home({ questions }) {
	const audioRef = useRef();
	const [ userTriggered, setUserTriggered ] = useState(false);
	const [ currentIndex, setCurrentIndex ] = useState(0);
	const [ replayTime, setReplayTime ] = useState(-1);
	const currentQuestion = useMemo(() => questions[currentIndex], [ currentIndex ]);
	const isReplayLimitReached = useMemo(() => replayTime >= MAX_NUM_REPLAY, [ replayTime, MAX_NUM_REPLAY ]);

	const playAudio = (e) => {
		audioRef.current.play();
	};

	const pauseAudio = (e) => {
		audioRef.current.pause();
	};

	const stopAudio = (e) => {
		pauseAudio();
		audioRef.current.currentTime = 0;
	};

	const replayQuestion = (e) => {
		if (!userTriggered) setUserTriggered(true);
		stopAudio();
		playAudio();
		setReplayTime((time) => (time < MAX_NUM_REPLAY ? time + 1 : MAX_NUM_REPLAY));
	};

	const nextQuestion = (e) => {
		pauseAudio();
		setReplayTime(-1);
		setCurrentIndex((index) => (index < questions.length - 1 ? index + 1 : 0));
	};

	const prevQuestion = (e) => {
		pauseAudio();
		setReplayTime(-1);
		setCurrentIndex((index) => (index > 0 ? index - 1 : questions.length - 1));
	};

	// next vh 100%
	useEffect(() => {
		const appHeight = () => {
			const doc = document.documentElement;
			doc.style.setProperty('--vh', `${(window.innerHeight * 0.01).toFixed(2)}px`);
		};
		window.addEventListener('resize', appHeight);
		appHeight();

		return () => {
			window.removeEventListener('resize', appHeight);
		};
	}, []);

	// play audio when the current question is changed
	useEffect(
		() => {
			playAudio();
		},
		[ currentQuestion ]
	);

	// setup audio context to calculate the amplitude
	const { amplitude, calculateAmplitude } = useWebAudio(audioRef.current, userTriggered);
	useRaf(calculateAmplitude, userTriggered);	// use requestAnimationFrame to calucalte current amplitude

	return (
		<Container>
			<Head>
				<title>Say My Interview Questions</title>
				<meta name="description" content="Generated by create next app" />
				<link rel="icon" href="/favicon.ico" />
				<link
					href="//fonts.googleapis.com/css2?family=Playfair+Display:ital@0;1&display=swap"
					rel="stylesheet"
				/>
			</Head>
			<Main>
				<Facade
					currentQuestion={currentQuestion}
					amplitude={amplitude}
					replayTime={replayTime}
					onReplayButtonClick={replayQuestion}
					isReplayLimitReached={isReplayLimitReached}
				/>
				<Controls onPrevButtonClick={prevQuestion} onNextButtonClick={nextQuestion} />
				<Audio ref={audioRef} src={currentQuestion.src} />
			</Main>
		</Container>
	);
}

const shuffledArray = (array) => array.sort(() => 0.5 - Math.random());

export async function getStaticProps() {
	const query = `
		*[_type == "post"]{
			"id": _id,
			"slug": slug.current,
			"src": manuscript.asset->url,
			"title": description
		}
	`;
	const fetchedQuestions = await client.fetch(query);
	const fetchedQuestionsWithNumber = fetchedQuestions.map((q, i) => ({ ...q, number: q.slug.split('-')[1] }));
	// const localData = questionData.data.map((q, i) => ({ ...q, number: i, src: `/audios/question-${i}.mp3` }));
	return {
		props: {
			questions: shuffledArray(fetchedQuestionsWithNumber)
			// questions: shuffledArray(localData)
		}
	};
}
